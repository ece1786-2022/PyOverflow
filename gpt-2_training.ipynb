{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-03T23:19:58.636744Z","iopub.execute_input":"2022-12-03T23:19:58.637197Z","iopub.status.idle":"2022-12-03T23:19:58.707226Z","shell.execute_reply.started":"2022-12-03T23:19:58.637091Z","shell.execute_reply":"2022-12-03T23:19:58.706094Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/builtin-types/built-in-types.json\n/kaggle/input/combined/combined.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:19:59.878465Z","iopub.execute_input":"2022-12-03T23:19:59.878828Z","iopub.status.idle":"2022-12-03T23:20:00.245298Z","shell.execute_reply.started":"2022-12-03T23:19:59.878798Z","shell.execute_reply":"2022-12-03T23:20:00.244309Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"csv\", data_files=\"../input/combined/combined.csv\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:00.787468Z","iopub.execute_input":"2022-12-03T23:20:00.787815Z","iopub.status.idle":"2022-12-03T23:20:02.064169Z","shell.execute_reply.started":"2022-12-03T23:20:00.787787Z","shell.execute_reply":"2022-12-03T23:20:02.062965Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-2fab4a07e04d0590/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2fb31edd3e54965a85d2031a103f002"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5faabc9f9964ec1b27480b4cf24ce1f"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-2fab4a07e04d0590/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:02.066325Z","iopub.execute_input":"2022-12-03T23:20:02.066989Z","iopub.status.idle":"2022-12-03T23:20:02.075570Z","shell.execute_reply.started":"2022-12-03T23:20:02.066941Z","shell.execute_reply":"2022-12-03T23:20:02.074574Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['content', 'topic', 'label'],\n    num_rows: 298\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\ntokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize_function(examples):\n  return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:02.905073Z","iopub.execute_input":"2022-12-03T23:20:02.906357Z","iopub.status.idle":"2022-12-03T23:20:07.011439Z","shell.execute_reply.started":"2022-12-03T23:20:02.906314Z","shell.execute_reply":"2022-12-03T23:20:07.010389Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ed15fb87244fa58bdf318ac81664e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5b407ae4694aaba71248dce7d49e9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8639da28c73949dbab5dda6f5d7f0bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f380574d2ff40a38d745dc38a713a3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ddda04889624cd286efb765b7843022"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"topic\",\"content\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:07.013768Z","iopub.execute_input":"2022-12-03T23:20:07.014165Z","iopub.status.idle":"2022-12-03T23:20:09.889313Z","shell.execute_reply.started":"2022-12-03T23:20:07.014127Z","shell.execute_reply":"2022-12-03T23:20:09.888202Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 298\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = tokenized_datasets.shuffle(seed=42).select(range(0,190))\neval_dataset = tokenized_datasets.shuffle(seed=42).select(range(190,298))","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:09.890894Z","iopub.execute_input":"2022-12-03T23:20:09.891629Z","iopub.status.idle":"2022-12-03T23:20:09.910822Z","shell.execute_reply.started":"2022-12-03T23:20:09.891586Z","shell.execute_reply":"2022-12-03T23:20:09.909813Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:09.912485Z","iopub.execute_input":"2022-12-03T23:20:09.913374Z","iopub.status.idle":"2022-12-03T23:20:09.918795Z","shell.execute_reply.started":"2022-12-03T23:20:09.913339Z","shell.execute_reply":"2022-12-03T23:20:09.917891Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"gpt2-medium\", num_labels=4, vocab_size= vocab_size, pad_token_id=tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:20:09.920412Z","iopub.execute_input":"2022-12-03T23:20:09.921570Z","iopub.status.idle":"2022-12-03T23:21:11.303366Z","shell.execute_reply.started":"2022-12-03T23:20:09.921534Z","shell.execute_reply":"2022-12-03T23:21:11.301729Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234398668eec483d9ee585cfff8c24c5"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\", num_train_epochs=2, per_device_train_batch_size=2, per_device_eval_batch_size=2,logging_dir=\"test_trainer\", evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:21:11.306440Z","iopub.execute_input":"2022-12-03T23:21:11.306853Z","iopub.status.idle":"2022-12-03T23:21:19.954048Z","shell.execute_reply.started":"2022-12-03T23:21:11.306811Z","shell.execute_reply":"2022-12-03T23:21:19.952474Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom datasets import load_metric\n\nmetric = load_metric(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:21:19.959547Z","iopub.execute_input":"2022-12-03T23:21:19.960063Z","iopub.status.idle":"2022-12-03T23:21:20.896955Z","shell.execute_reply.started":"2022-12-03T23:21:19.960014Z","shell.execute_reply":"2022-12-03T23:21:20.895986Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63479227da8d476c961b7b69b0e1f3d6"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:21:20.898296Z","iopub.execute_input":"2022-12-03T23:21:20.898674Z","iopub.status.idle":"2022-12-03T23:21:20.904673Z","shell.execute_reply.started":"2022-12-03T23:21:20.898639Z","shell.execute_reply":"2022-12-03T23:21:20.903563Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(output_dir=\"/test_trainer\", num_train_epochs=3, per_device_train_batch_size=1, per_device_eval_batch_size=1,logging_dir=\"test_trainer\", evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:04.703249Z","iopub.execute_input":"2022-12-03T23:22:04.703790Z","iopub.status.idle":"2022-12-03T23:22:04.724481Z","shell.execute_reply.started":"2022-12-03T23:22:04.703675Z","shell.execute_reply":"2022-12-03T23:22:04.723224Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:06.410871Z","iopub.execute_input":"2022-12-03T23:22:06.411408Z","iopub.status.idle":"2022-12-03T23:22:06.431023Z","shell.execute_reply.started":"2022-12-03T23:22:06.411356Z","shell.execute_reply":"2022-12-03T23:22:06.430097Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:07.341943Z","iopub.execute_input":"2022-12-03T23:22:07.342574Z","iopub.status.idle":"2022-12-03T23:22:07.899776Z","shell.execute_reply.started":"2022-12-03T23:22:07.342498Z","shell.execute_reply":"2022-12-03T23:22:07.898251Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:08.436027Z","iopub.execute_input":"2022-12-03T23:22:08.436682Z","iopub.status.idle":"2022-12-03T23:22:08.445265Z","shell.execute_reply.started":"2022-12-03T23:22:08.436634Z","shell.execute_reply":"2022-12-03T23:22:08.443628Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# setting device on GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:09.345854Z","iopub.execute_input":"2022-12-03T23:22:09.346385Z","iopub.status.idle":"2022-12-03T23:22:09.359517Z","shell.execute_reply.started":"2022-12-03T23:22:09.346343Z","shell.execute_reply":"2022-12-03T23:22:09.357703Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Using device: cuda\n\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-12-03T23:22:10.017571Z","iopub.execute_input":"2022-12-03T23:22:10.018153Z","iopub.status.idle":"2022-12-03T23:29:02.080346Z","shell.execute_reply.started":"2022-12-03T23:22:10.018109Z","shell.execute_reply":"2022-12-03T23:29:02.079330Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 190\n  Num Epochs = 3\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 285\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [285/285 06:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.972500</td>\n      <td>0.731481</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.644241</td>\n      <td>0.842593</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.503582</td>\n      <td>0.851852</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 108\n  Batch size = 2\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 108\n  Batch size = 2\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 108\n  Batch size = 2\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=285, training_loss=0.8017127321477522, metrics={'train_runtime': 412.0166, 'train_samples_per_second': 1.383, 'train_steps_per_second': 0.692, 'total_flos': 1058733136281600.0, 'train_loss': 0.8017127321477522, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}