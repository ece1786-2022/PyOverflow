{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-20T19:32:39.657245Z","iopub.execute_input":"2022-11-20T19:32:39.657555Z","iopub.status.idle":"2022-11-20T19:32:39.700387Z","shell.execute_reply.started":"2022-11-20T19:32:39.657486Z","shell.execute_reply":"2022-11-20T19:32:39.699557Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/builtin-types/built-in-types.json\n/kaggle/input/combined/combined.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:39.703277Z","iopub.execute_input":"2022-11-20T19:32:39.703975Z","iopub.status.idle":"2022-11-20T19:32:40.048772Z","shell.execute_reply.started":"2022-11-20T19:32:39.703938Z","shell.execute_reply":"2022-11-20T19:32:40.047810Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"csv\", data_files=\"../input/combined/combined.csv\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:40.053681Z","iopub.execute_input":"2022-11-20T19:32:40.056190Z","iopub.status.idle":"2022-11-20T19:32:41.040458Z","shell.execute_reply.started":"2022-11-20T19:32:40.056150Z","shell.execute_reply":"2022-11-20T19:32:41.039452Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-16f75a255ac57dc1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261cef813b444791982c2822126d8f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"660a74edde5347a2b88c91a4df4c65f8"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-16f75a255ac57dc1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:41.042889Z","iopub.execute_input":"2022-11-20T19:32:41.043315Z","iopub.status.idle":"2022-11-20T19:32:41.051883Z","shell.execute_reply.started":"2022-11-20T19:32:41.043273Z","shell.execute_reply":"2022-11-20T19:32:41.050694Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['content', 'topic', 'label'],\n    num_rows: 176\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\ntokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize_function(examples):\n  return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:49.698172Z","iopub.execute_input":"2022-11-20T19:32:49.698546Z","iopub.status.idle":"2022-11-20T19:32:53.190691Z","shell.execute_reply.started":"2022-11-20T19:32:49.698510Z","shell.execute_reply":"2022-11-20T19:32:53.189705Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad30fe9d1bdd444c912615bd70f9f32e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2212d9e4ac6c4a94b93761856e0ab189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b12e515ad744b3599fa17fba3b20707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258089e4dcec4dfcae1852298036820f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1173f5f64b4b519142c2eeb2d30d45"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"topic\",\"content\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:53.192746Z","iopub.execute_input":"2022-11-20T19:32:53.193113Z","iopub.status.idle":"2022-11-20T19:32:54.847946Z","shell.execute_reply.started":"2022-11-20T19:32:53.193073Z","shell.execute_reply":"2022-11-20T19:32:54.846714Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 176\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = tokenized_datasets.shuffle(seed=42).select(range(0,140))\neval_dataset = tokenized_datasets.shuffle(seed=42).select(range(140,176))","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:55.158484Z","iopub.execute_input":"2022-11-20T19:32:55.159596Z","iopub.status.idle":"2022-11-20T19:32:55.179089Z","shell.execute_reply.started":"2022-11-20T19:32:55.159551Z","shell.execute_reply":"2022-11-20T19:32:55.178155Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:56.354971Z","iopub.execute_input":"2022-11-20T19:32:56.355418Z","iopub.status.idle":"2022-11-20T19:32:56.360860Z","shell.execute_reply.started":"2022-11-20T19:32:56.355376Z","shell.execute_reply":"2022-11-20T19:32:56.359574Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"gpt2-medium\", num_labels=2, vocab_size= vocab_size, pad_token_id=tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:32:57.192488Z","iopub.execute_input":"2022-11-20T19:32:57.192859Z","iopub.status.idle":"2022-11-20T19:34:09.613019Z","shell.execute_reply.started":"2022-11-20T19:32:57.192825Z","shell.execute_reply":"2022-11-20T19:34:09.611733Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c58cb5117ae4982b7ab2740968ed49b"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\", num_train_epochs=5, per_device_train_batch_size=32, per_device_eval_batch_size=32,logging_dir=\"test_trainer\", evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:09.615263Z","iopub.execute_input":"2022-11-20T19:34:09.615683Z","iopub.status.idle":"2022-11-20T19:34:14.749272Z","shell.execute_reply.started":"2022-11-20T19:34:09.615635Z","shell.execute_reply":"2022-11-20T19:34:14.748250Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom datasets import load_metric\n\nmetric = load_metric(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:14.753105Z","iopub.execute_input":"2022-11-20T19:34:14.753400Z","iopub.status.idle":"2022-11-20T19:34:16.061416Z","shell.execute_reply.started":"2022-11-20T19:34:14.753373Z","shell.execute_reply":"2022-11-20T19:34:16.060408Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e58340301544ca2a14c2b6e28ed6ea0"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:21.689809Z","iopub.execute_input":"2022-11-20T19:34:21.690519Z","iopub.status.idle":"2022-11-20T19:34:21.697709Z","shell.execute_reply.started":"2022-11-20T19:34:21.690478Z","shell.execute_reply":"2022-11-20T19:34:21.695483Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(output_dir=\"/test_trainer\", num_train_epochs=3, per_device_train_batch_size=4, per_device_eval_batch_size=4,logging_dir=\"test_trainer\", evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:22.667626Z","iopub.execute_input":"2022-11-20T19:34:22.668499Z","iopub.status.idle":"2022-11-20T19:34:22.676098Z","shell.execute_reply.started":"2022-11-20T19:34:22.668462Z","shell.execute_reply":"2022-11-20T19:34:22.674886Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:23.447547Z","iopub.execute_input":"2022-11-20T19:34:23.448268Z","iopub.status.idle":"2022-11-20T19:34:29.000767Z","shell.execute_reply.started":"2022-11-20T19:34:23.448229Z","shell.execute_reply":"2022-11-20T19:34:28.999583Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:29.005047Z","iopub.execute_input":"2022-11-20T19:34:29.005340Z","iopub.status.idle":"2022-11-20T19:34:29.010073Z","shell.execute_reply.started":"2022-11-20T19:34:29.005310Z","shell.execute_reply":"2022-11-20T19:34:29.008917Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:30.715870Z","iopub.execute_input":"2022-11-20T19:34:30.716250Z","iopub.status.idle":"2022-11-20T19:34:30.721206Z","shell.execute_reply.started":"2022-11-20T19:34:30.716216Z","shell.execute_reply":"2022-11-20T19:34:30.720165Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# setting device on GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:32.398711Z","iopub.execute_input":"2022-11-20T19:34:32.399877Z","iopub.status.idle":"2022-11-20T19:34:32.406287Z","shell.execute_reply.started":"2022-11-20T19:34:32.399832Z","shell.execute_reply":"2022-11-20T19:34:32.405238Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Using device: cuda\n\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:34:33.562767Z","iopub.execute_input":"2022-11-20T19:34:33.564073Z","iopub.status.idle":"2022-11-20T19:39:11.147641Z","shell.execute_reply.started":"2022-11-20T19:34:33.564016Z","shell.execute_reply":"2022-11-20T19:39:11.146705Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 140\n  Num Epochs = 3\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 210\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [210/210 04:22, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.686600</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.645934</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.743750</td>\n      <td>0.888889</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 36\n  Batch size = 2\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 36\n  Batch size = 2\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 36\n  Batch size = 2\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=210, training_loss=0.488860103062221, metrics={'train_runtime': 277.548, 'train_samples_per_second': 1.513, 'train_steps_per_second': 0.757, 'total_flos': 780113868226560.0, 'train_loss': 0.488860103062221, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}